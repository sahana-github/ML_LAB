{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Prg2_ANN_MLP.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"uvfdlUCQjHbW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628457908500,"user_tz":-330,"elapsed":341,"user":{"displayName":"Kushal Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvUgEOgk3Zuv0o9oKhvBT8V4h9hpf4Cce5xu6uA-I=s64","userId":"03839171573517498269"}},"outputId":"ec593c75-305e-4653-e3b2-89c201fb670a"},"source":["import numpy as np\n","X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n","y = np.array(([92], [86], [89]), dtype=float)\n","#print(X),k\n","deno = np.amax(X,axis=0)\n","print(\"Demo\",deno)\n","X = X/deno\n","y = y/100\n","print(X)\n","print(y)\n","\n","\n","\n","def sigmoid (x):\n","    return 1/(1 + np.exp(-x))\n","\n","def derivatives_sigmoid(x): \n","    return x * (1 - x)\n","\n","iteration = 100\t#Setting training iterations\n","error_rate =0.1 \t\t#Setting learning rate-error rate\n","inputlayer_neurons = 2 \t\t#number of features in data set\n","hiddenlayer_neurons = 3 \t#number of hidden layers neurons\n","output_neurons = 1 \t\t#number of neurons at output layer\n","\n","\n","weight_hidden = np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))\n","#print(weight_hidden)\n","bias_hidden = np.random.uniform(size=(1,hiddenlayer_neurons))\n","#print(\"bias value\",bias_hidden)\n","weight_output = np.random.uniform(size=(hiddenlayer_neurons,output_neurons))\n","bias_output = np.random.uniform(size=(1,output_neurons))\n","print(X.shape)\n","\n","for i in range(iteration):\n","    hidden_input=np.dot(X,weight_hidden) # h1 = w1*x1+w2*x2+w3*x3\n","    hidden_input =hidden_input + bias_hidden\n","    output_hidden_layer = sigmoid( hidden_input)\n","    #print(output_hidden_layer)\n","    actual_output = np.dot(output_hidden_layer,weight_output)+bias_output\n","    y_output = sigmoid(actual_output)\n","    #print(\"predicted output\",y_output)\n","    \n","    \n","    #Backpropagation\n","    EO = y-y_output\n","    outgrad = derivatives_sigmoid(y_output)\n","    d_output = EO* outgrad\n","    EH = d_output.dot(weight_output.T)\n","    hiddengrad = derivatives_sigmoid(output_hidden_layer)\n","    d_hiddenlayer = EH * hiddengrad\n","    \n","    weight_output += output_hidden_layer.T.dot(d_output) *error_rate \n","    weight_hidden += X.T.dot(d_hiddenlayer) *error_rate\n","\n","print(\"Input: \\n\" + str(X)) \n","print(\"Actual Output: \\n\" + str(y))\n","print(\"Predicted Output: \\n\" ,y_output)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Demo [3. 9.]\n","[[0.66666667 1.        ]\n"," [0.33333333 0.55555556]\n"," [1.         0.66666667]]\n","[[0.92]\n"," [0.86]\n"," [0.89]]\n","(3, 2)\n","Input: \n","[[0.66666667 1.        ]\n"," [0.33333333 0.55555556]\n"," [1.         0.66666667]]\n","Actual Output: \n","[[0.92]\n"," [0.86]\n"," [0.89]]\n","Predicted Output: \n"," [[0.87270462]\n"," [0.85638623]\n"," [0.87076509]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-Z9CrHNjjJQg"},"source":[""],"execution_count":null,"outputs":[]}]}